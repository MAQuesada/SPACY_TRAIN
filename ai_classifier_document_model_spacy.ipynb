{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train text classifier model using *News Category Dataset***\n",
    "\n",
    "* https://www.kaggle.com/datasets/rmisra/news-category-dataset\n",
    "\n",
    "This Dataset contains 41 categories, and you can see that the data is reasonably unbalanced, so we will only use the data from 24 categories and use a subset of the data from each category for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORIES IN THE DATASET\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('POLITICS', 35602),\n",
       " ('WELLNESS', 17945),\n",
       " ('ENTERTAINMENT', 17362),\n",
       " ('TRAVEL', 9900),\n",
       " ('STYLE & BEAUTY', 9814),\n",
       " ('PARENTING', 8791),\n",
       " ('HEALTHY LIVING', 6694),\n",
       " ('QUEER VOICES', 6347),\n",
       " ('FOOD & DRINK', 6340),\n",
       " ('BUSINESS', 5992),\n",
       " ('COMEDY', 5400),\n",
       " ('SPORTS', 5077),\n",
       " ('BLACK VOICES', 4583),\n",
       " ('HOME & LIVING', 4320),\n",
       " ('PARENTS', 3955),\n",
       " ('THE WORLDPOST', 3664),\n",
       " ('WEDDINGS', 3653),\n",
       " ('WOMEN', 3572),\n",
       " ('CRIME', 3562),\n",
       " ('IMPACT', 3484),\n",
       " ('DIVORCE', 3426),\n",
       " ('WORLD NEWS', 3299),\n",
       " ('MEDIA', 2944),\n",
       " ('WEIRD NEWS', 2777),\n",
       " ('GREEN', 2622),\n",
       " ('WORLDPOST', 2579),\n",
       " ('RELIGION', 2577),\n",
       " ('STYLE', 2254),\n",
       " ('SCIENCE', 2206),\n",
       " ('TECH', 2104),\n",
       " ('TASTE', 2096),\n",
       " ('MONEY', 1756),\n",
       " ('ARTS', 1509),\n",
       " ('ENVIRONMENT', 1444),\n",
       " ('FIFTY', 1401),\n",
       " ('GOOD NEWS', 1398),\n",
       " ('U.S. NEWS', 1377),\n",
       " ('ARTS & CULTURE', 1339),\n",
       " ('COLLEGE', 1144),\n",
       " ('LATINO VOICES', 1130),\n",
       " ('CULTURE & ARTS', 1074),\n",
       " ('EDUCATION', 1014)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('spacy_files/News_Category_Dataset_v3.json') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "import json\n",
    "\n",
    "categories_count = {}\n",
    "\n",
    "# Iterar a través de cada diccionario en la lista\n",
    "for dic in lines:\n",
    "    category = json.loads(dic)['category']\n",
    "    \n",
    "    # Actualizar el recuento de la categoría\n",
    "    if category in categories_count:\n",
    "        categories_count[category] += 1\n",
    "    else:\n",
    "        categories_count[category] = 1\n",
    "\n",
    "print('CATEGORIES IN THE DATASET')\n",
    "sorted(categories_count.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_categories = ['POLITICS', 'WELLNESS', 'ENTERTAINMENT', 'TRAVEL', 'STYLE & BEAUTY', 'HEALTHY LIVING', 'FOOD & DRINK', 'BUSINESS', 'COMEDY', 'SPORTS', 'HOME & LIVING', 'WEDDINGS', 'WOMEN', 'CRIME', 'MEDIA',  'RELIGION', 'STYLE', 'SCIENCE', 'TECH', 'MONEY', 'ARTS', 'ENVIRONMENT','WORLD NEWS', 'GOOD NEWS', 'WEIRD NEWS', 'COLLEGE', 'EDUCATION']\n",
    "\n",
    "data_dict = {category: [] for category in interesting_categories}\n",
    "\n",
    "for line in lines : \n",
    "    line_dict = json.loads(line)\n",
    "    if line_dict[\"category\"] in interesting_categories :\n",
    "        data_dict[line_dict[\"category\"]].append(line_dict[\"headline\"])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('POLITICS', 35602),\n",
       " ('WELLNESS', 17945),\n",
       " ('ENTERTAINMENT', 17362),\n",
       " ('TRAVEL', 9900),\n",
       " ('STYLE & BEAUTY', 9814),\n",
       " ('NEWS', 7474),\n",
       " ('HEALTHY LIVING', 6694),\n",
       " ('FOOD & DRINK', 6340),\n",
       " ('BUSINESS', 5992),\n",
       " ('COMEDY', 5400),\n",
       " ('SPORTS', 5077),\n",
       " ('HOME & LIVING', 4320),\n",
       " ('WEDDINGS', 3653),\n",
       " ('WOMEN', 3572),\n",
       " ('CRIME', 3562),\n",
       " ('MEDIA', 2944),\n",
       " ('RELIGION', 2577),\n",
       " ('STYLE', 2254),\n",
       " ('SCIENCE', 2206),\n",
       " ('EDUCATION', 2158),\n",
       " ('TECH', 2104),\n",
       " ('MONEY', 1756),\n",
       " ('ARTS', 1509),\n",
       " ('ENVIRONMENT', 1444)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join COLLEGE with COLLEGE\n",
    "data_dict['EDUCATION'].extend(data_dict.pop('COLLEGE'))\n",
    "\n",
    "# join all NEWS Categories\n",
    "data_dict['NEWS'] = []\n",
    "data_dict['NEWS'].extend(data_dict.pop('WEIRD NEWS'))\n",
    "data_dict['NEWS'].extend(data_dict.pop('GOOD NEWS'))\n",
    "data_dict['NEWS'].extend(data_dict.pop('WORLD NEWS'))\n",
    "\n",
    "# see the instances for each categories \n",
    "sorted([(key,len(data_dict[key])) for key in data_dict.keys() ], key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid some imbalance in the data we will only use a maximum of 5500 of each category for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE OF DATA: \n",
      "NUMBER OF CATEGORIES: 24\n",
      "TRAIN: 75228  VALIDATION: 13165  EVALUATION: 5643\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "INSTANCE_MAX = 5500\n",
    "data = []\n",
    "category = []\n",
    "for key, values_list in data_dict.items():\n",
    "    random.shuffle(values_list)\n",
    "    data.extend(values_list[:INSTANCE_MAX])\n",
    "    category.extend([key] * len(values_list[:INSTANCE_MAX]))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, category, test_size=0.20, stratify=category, random_state=42\n",
    ")\n",
    "\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "    X_test, y_test, test_size=0.3, stratify=y_test, random_state=42\n",
    ")\n",
    "\n",
    "print(f'SHAPE OF DATA: \\nNUMBER OF CATEGORIES: {len(data_dict)}\\nTRAIN: {len(X_train)}  VALIDATION: {len(X_dev)}  EVALUATION: {len(X_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U pip setuptools wheel\n",
    "! pip install -U 'spacy[cuda12x,transformers,lookups]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "# to use GPU, but need Cupy installed and compatible wirh CUDAS\n",
    "# spacy.require_gpu() \n",
    "\n",
    "\n",
    "def convert(text_list: list, label_list: list, outfile: str):\n",
    "    \"\"\"Performing the data using the DocBin structure, which makes\n",
    "    data manipulations in spaCy more efficient and save the data in disk.\n",
    "    \"\"\"\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    db = DocBin()\n",
    "    for text, label in zip(text_list, label_list):\n",
    "        doc = nlp.make_doc(text)\n",
    "        doc.cats = {cat: 0 for cat in data_dict.keys()}\n",
    "        doc.cats[label] = 1\n",
    "        db.add(doc)\n",
    "    db.to_disk(outfile)\n",
    "\n",
    "\n",
    "convert(X_train, y_train, \"spacy_files/news_train.spacy\")\n",
    "convert(X_dev, y_dev, \"spacy_files/news_dev.spacy\")\n",
    "convert(X_test, y_test, \"spacy_files/news_test.spacy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: textcat_multilabel\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "train_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train train_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config --pipeline textcat_multilabel train_config.cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-10 03:15:06,550] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
      "\u001b[38;5;2m✔ Created output directory: spacy_files/24categories_news_model\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: spacy_files/24categories_news_model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2024-03-10 03:15:07,009] [INFO] Set up nlp object from config\n",
      "[2024-03-10 03:15:07,016] [DEBUG] Loading corpus from path: spacy_files/news_dev.spacy\n",
      "[2024-03-10 03:15:07,016] [DEBUG] Loading corpus from path: spacy_files/news_train.spacy\n",
      "[2024-03-10 03:15:07,016] [INFO] Pipeline: ['textcat_multilabel']\n",
      "[2024-03-10 03:15:07,019] [INFO] Created vocabulary\n",
      "[2024-03-10 03:15:07,019] [INFO] Finished initializing nlp object\n",
      "[2024-03-10 03:15:18,080] [INFO] Initialized pipeline components: ['textcat_multilabel']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[2024-03-10 03:15:18,087] [DEBUG] Loading corpus from path: spacy_files/news_dev.spacy\n",
      "[2024-03-10 03:15:18,088] [DEBUG] Loading corpus from path: spacy_files/news_train.spacy\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.04       49.73    0.50\n",
      "  0     200           7.85       64.69    0.65\n",
      "  0     400           7.73       70.31    0.70\n",
      "  0     600           7.49       73.64    0.74\n",
      "  0     800           7.26       77.78    0.78\n",
      "  0    1000           7.06       80.60    0.81\n",
      "  0    1200           6.70       83.39    0.83\n",
      "  0    1400           6.34       85.47    0.85\n",
      "  0    1600           6.08       87.11    0.87\n",
      "  0    1800           5.94       88.78    0.89\n",
      "  0    2000           5.68       89.92    0.90\n",
      "  0    2200           5.49       90.92    0.91\n",
      "  1    2400           5.03       91.44    0.91\n",
      "  1    2600           4.90       91.86    0.92\n",
      "  1    2800           4.87       92.26    0.92\n",
      "  1    3000           4.80       92.52    0.93\n",
      "  2    3200           4.49       92.64    0.93\n",
      "  2    3400           4.33       92.89    0.93\n",
      "  2    3600           4.40       92.99    0.93\n",
      "  2    3800           4.39       93.28    0.93\n",
      "  3    4000           4.21       93.29    0.93\n",
      "  3    4200           3.95       93.39    0.93\n",
      "  3    4400           4.06       93.36    0.93\n",
      "  3    4600           4.18       93.58    0.94\n",
      "  4    4800           4.03       93.55    0.94\n",
      "  4    5000           3.72       93.51    0.94\n",
      "  4    5200           3.79       93.62    0.94\n",
      "  4    5400           3.90       93.72    0.94\n",
      "  5    5600           3.84       93.60    0.94\n",
      "  5    5800           3.47       93.67    0.94\n",
      "  5    6000           3.53       93.74    0.94\n",
      "  5    6200           3.62       93.74    0.94\n",
      "  5    6400           3.68       93.91    0.94\n",
      "  6    6600           3.18       93.70    0.94\n",
      "  6    6800           3.30       93.75    0.94\n",
      "  6    7000           3.43       93.71    0.94\n",
      "  6    7200           3.54       93.90    0.94\n",
      "  7    7400           3.15       93.73    0.94\n",
      "  7    7600           3.18       93.70    0.94\n",
      "  7    7800           3.25       93.72    0.94\n",
      "  7    8000           3.31       93.79    0.94\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "spacy_files/24categories_news_model/model-last\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy train spacy_files/train_config.cfg --paths.train spacy_files/news_train.spacy  --paths.dev spacy_files/news_dev.spacy --output spacy_files/24categories_news_model --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK                   100.00\n",
      "TEXTCAT (macro AUC)   94.10 \n",
      "SPEED                 39741 \n",
      "\n",
      "\u001b[1m\n",
      "=========================== Textcat F (per label) ===========================\u001b[0m\n",
      "\n",
      "                     P       R       F\n",
      "POLITICS         70.63   53.94   61.17\n",
      "WELLNESS         59.72   38.18   46.58\n",
      "ENTERTAINMENT    63.77   53.33   58.09\n",
      "TRAVEL           77.91   60.91   68.37\n",
      "STYLE & BEAUTY   76.90   70.61   73.62\n",
      "HEALTHY LIVING   58.62   36.06   44.65\n",
      "FOOD & DRINK     84.36   70.30   76.69\n",
      "BUSINESS         65.24   41.52   50.74\n",
      "COMEDY           72.05   50.93   59.67\n",
      "SPORTS           73.70   74.43   74.06\n",
      "HOME & LIVING    85.07   66.02   74.35\n",
      "WEDDINGS         91.13   84.47   87.68\n",
      "WOMEN            58.52   48.13   52.82\n",
      "CRIME            72.58   63.08   67.50\n",
      "MEDIA            69.18   57.06   62.54\n",
      "RELIGION         74.22   61.29   67.14\n",
      "STYLE            72.00   26.67   38.92\n",
      "SCIENCE          70.51   41.67   52.38\n",
      "TECH             57.76   53.17   55.37\n",
      "MONEY            62.07   34.29   44.17\n",
      "ARTS             54.84   18.68   27.87\n",
      "ENVIRONMENT      71.11   36.78   48.48\n",
      "EDUCATION        69.57   36.92   48.24\n",
      "NEWS             66.35   42.42   51.76\n",
      "\n",
      "\u001b[1m\n",
      "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
      "\n",
      "                 ROC AUC\n",
      "POLITICS            0.94\n",
      "WELLNESS            0.93\n",
      "ENTERTAINMENT       0.93\n",
      "TRAVEL              0.95\n",
      "STYLE & BEAUTY      0.97\n",
      "HEALTHY LIVING      0.93\n",
      "FOOD & DRINK        0.98\n",
      "BUSINESS            0.91\n",
      "COMEDY              0.92\n",
      "SPORTS              0.96\n",
      "HOME & LIVING       0.97\n",
      "WEDDINGS            0.98\n",
      "WOMEN               0.92\n",
      "CRIME               0.97\n",
      "MEDIA               0.95\n",
      "RELIGION            0.95\n",
      "STYLE               0.95\n",
      "SCIENCE             0.94\n",
      "TECH                0.94\n",
      "MONEY               0.94\n",
      "ARTS                0.92\n",
      "ENVIRONMENT         0.90\n",
      "EDUCATION           0.93\n",
      "NEWS                0.91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy evaluate spacy_files/24categories_news_model/model-best/ spacy_files/news_test.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'POLITICS': 0.04754519462585449,\n",
       " 'WELLNESS': 0.001057898043654859,\n",
       " 'ENTERTAINMENT': 0.004479375202208757,\n",
       " 'TRAVEL': 0.0006009417702443898,\n",
       " 'STYLE & BEAUTY': 0.0008289911784231663,\n",
       " 'HEALTHY LIVING': 0.00559990806505084,\n",
       " 'FOOD & DRINK': 2.574278914835304e-05,\n",
       " 'BUSINESS': 0.4946499466896057,\n",
       " 'COMEDY': 0.001905512879602611,\n",
       " 'SPORTS': 0.0007069869316183031,\n",
       " 'HOME & LIVING': 0.0002976031100843102,\n",
       " 'WEDDINGS': 6.09952439845074e-05,\n",
       " 'WOMEN': 0.05362309515476227,\n",
       " 'CRIME': 0.004431582521647215,\n",
       " 'MEDIA': 0.09137539565563202,\n",
       " 'RELIGION': 0.005778406746685505,\n",
       " 'STYLE': 0.0006475687841884792,\n",
       " 'SCIENCE': 0.002787437289953232,\n",
       " 'TECH': 0.26404523849487305,\n",
       " 'MONEY': 0.0023959362879395485,\n",
       " 'ARTS': 0.0034477850422263145,\n",
       " 'ENVIRONMENT': 0.0014956939266994596,\n",
       " 'EDUCATION': 0.007798791863024235,\n",
       " 'NEWS': 0.004413879942148924}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"spacy_files/24categories_news_model/model-best\")\n",
    "doc=nlp(\"Women entrepreneurs play a pivotal role in shaping industries, fostering economic growth, and driving positive change in communities worldwide.\")\n",
    "doc.cats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
