{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Build a binary text classification (Sentiment Analysis) using our custom TextCategorizer component.**\n",
    "\n",
    "https://medium.com/@johnidouglasmarangon/building-a-text-classification-model-with-spacy-3-x-57e59fa50547"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The dataset is labeled for a tweet sentiment analysis with two categories, positive and negative in Brazilian Portuguese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mas tu não és feio :( @SavageFluxXx__</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@SamaraPaivas Você que pensa :)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>te amo demais :( https://t.co/leUzS65WrG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nicko_donis lindo! :)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@B_kirikihira Oi, tem sim! Visite nossos canai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  sentiment\n",
       "0              Mas tu não és feio :( @SavageFluxXx__          0\n",
       "1                    @SamaraPaivas Você que pensa :)          1\n",
       "2           te amo demais :( https://t.co/leUzS65WrG          0\n",
       "3                             @nicko_donis lindo! :)          1\n",
       "4  @B_kirikihira Oi, tem sim! Visite nossos canai...          1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://gist.githubusercontent.com/johnidm/582cfeadd2bf418df4539c9422f824d2/raw/twitter-sentiment-pt-BR-md-2-l.csv\")\n",
    "df.head()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mas tu não és feio :( @SavageFluxXx__</td>\n",
       "      <td>0</td>\n",
       "      <td>feio emocaonegativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@SamaraPaivas Você que pensa :)</td>\n",
       "      <td>1</td>\n",
       "      <td>pensa emocaopositiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>te amo demais :( https://t.co/leUzS65WrG</td>\n",
       "      <td>0</td>\n",
       "      <td>emocaonegativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nicko_donis lindo! :)</td>\n",
       "      <td>1</td>\n",
       "      <td>lindo emocaopositiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@B_kirikihira Oi, tem sim! Visite nossos canai...</td>\n",
       "      <td>1</td>\n",
       "      <td>visite canais saiba projeto incrivel emocaopos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  sentiment  \\\n",
       "0              Mas tu não és feio :( @SavageFluxXx__          0   \n",
       "1                    @SamaraPaivas Você que pensa :)          1   \n",
       "2           te amo demais :( https://t.co/leUzS65WrG          0   \n",
       "3                             @nicko_donis lindo! :)          1   \n",
       "4  @B_kirikihira Oi, tem sim! Visite nossos canai...          1   \n",
       "\n",
       "                                    tweet_text_clean  \n",
       "0                                feio emocaonegativa  \n",
       "1                               pensa emocaopositiva  \n",
       "2                                     emocaonegativa  \n",
       "3                               lindo emocaopositiva  \n",
       "4  visite canais saiba projeto incrivel emocaopos...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.blank(\"pt\")\n",
    "\n",
    "REGX_USERNAME = r\"@[A-Za-z0-9$-_@.&+]+\"\n",
    "REGX_URL = r\"https?://[A-Za-z0-9./]+\"\n",
    "\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub(REGX_USERNAME, \" \", text)\n",
    "    text = re.sub(REGX_URL, \" \", text)\n",
    "\n",
    "    emojis = {\":)\": \"emocaopositiva\", \":(\": \"emocaonegativa\"}\n",
    "\n",
    "    for e in emojis:\n",
    "        text = text.replace(e, emojis[e])\n",
    "\n",
    "    tokens = [token.text for token in nlp(text)]\n",
    "\n",
    "    tokens = [\n",
    "        t\n",
    "        for t in tokens\n",
    "        if t not in STOP_WORDS and t not in string.punctuation and len(t) > 3\n",
    "    ]\n",
    "\n",
    "    tokens = [t for t in tokens if not t.isdigit()]\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "df[\"tweet_text_clean\"] = df[\"tweet_text\"].apply(preprocessing)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 20000 - Train:  15000 - Dev: 3000 - Test: 2000\n"
     ]
    }
   ],
   "source": [
    "dataset = list(df[[\"tweet_text_clean\", \"sentiment\"]].sample(frac=1).itertuples(index=False, name=None))\n",
    "train_data = dataset[:15000]\n",
    "dev_data = dataset[15000:18000]\n",
    "test_data = dataset[18000:]\n",
    "\n",
    "print(f\"Total: {len(dataset)} - Train:  {len(train_data)} - Dev: {len(dev_data)} - Test: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are performing the data using the DocBin structure, which makes data manipulations in spaCy more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "\n",
    "def convert(data, outfile):\n",
    "    db = DocBin()\n",
    "    docs = []\n",
    "    for doc, label in nlp.pipe(data, as_tuples=True):\n",
    "        doc.cats[\"POS\"] = label == 1\n",
    "        doc.cats[\"NEG\"] = label == 0\n",
    "        db.add(doc)\n",
    "    \n",
    "    db.to_disk(outfile)\n",
    "convert(train_data, \"resources/train.spacy\")\n",
    "convert(dev_data, \"resources/dev.spacy\")\n",
    "convert(test_data, \"resources/test.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Pipeline\n",
    "\n",
    "Training config files include all settings and hyperparameters for training your pipeline instead of providing lots of arguments on the command line or in a source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: pt\n",
      "- Pipeline: textcat\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config  --lang pt --pipeline textcat --optimize efficiency --force config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: resources\\model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ----------  ------\n",
      "  0       0          0.25       38.38    0.38\n",
      "  0     200          6.86       97.49    0.97\n",
      "  0     400          2.23       98.93    0.99\n",
      "  0     600          1.94       98.73    0.99\n",
      "  1     800          1.52       98.36    0.98\n",
      "  1    1000          1.16       98.93    0.99\n",
      "  2    1200          0.68       98.79    0.99\n",
      "  3    1400          0.32       98.79    0.99\n",
      "  4    1600          0.22       98.89    0.99\n",
      "  5    1800          0.09       98.89    0.99\n",
      "  7    2000          0.02       98.83    0.99\n",
      "  9    2200          0.06       98.83    0.99\n",
      " 11    2400          0.04       98.79    0.99\n",
      " 13    2600          0.03       98.73    0.99\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "resources\\model\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-08 18:38:50,651] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
      "[2024-03-08 18:38:50,830] [INFO] Set up nlp object from config\n",
      "[2024-03-08 18:38:50,849] [DEBUG] Loading corpus from path: resources\\dev.spacy\n",
      "[2024-03-08 18:38:50,852] [DEBUG] Loading corpus from path: resources\\train.spacy\n",
      "[2024-03-08 18:38:50,852] [INFO] Pipeline: ['textcat']\n",
      "[2024-03-08 18:38:50,856] [INFO] Created vocabulary\n",
      "[2024-03-08 18:38:50,856] [INFO] Finished initializing nlp object\n",
      "[2024-03-08 18:38:55,310] [INFO] Initialized pipeline components: ['textcat']\n",
      "[2024-03-08 18:38:55,332] [DEBUG] Loading corpus from path: resources\\dev.spacy\n",
      "[2024-03-08 18:38:55,334] [DEBUG] Loading corpus from path: resources\\train.spacy\n",
      "[2024-03-08 18:38:55,340] [DEBUG] Removed existing output directory: resources\\model\\model-best\n",
      "[2024-03-08 18:38:55,344] [DEBUG] Removed existing output directory: resources\\model\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --paths.train resources/train.spacy --paths.dev resources/dev.spacy --output resources/model --verbose\n",
    "\n",
    "\n",
    "# train from code\n",
    "# from spacy.cli.train import train\n",
    "\n",
    "# train(\n",
    "#     \"./config.cfg\",\n",
    "#     overrides={\n",
    "#         \"paths.train\": \"resources/train.spacy\",\n",
    "#         \"paths.dev\": \"resources/dev.spacy \",\n",
    "#     },\n",
    "#     output_path=\"resources/model\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pepeline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK                 100.00\n",
      "TEXTCAT (macro F)   99.15 \n",
      "SPEED               110252\n",
      "\n",
      "\u001b[1m\n",
      "=========================== Textcat F (per label) ===========================\u001b[0m\n",
      "\n",
      "          P       R       F\n",
      "POS   98.59   99.70   99.14\n",
      "NEG   99.70   98.61   99.15\n",
      "\n",
      "\u001b[1m\n",
      "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
      "\n",
      "      ROC AUC\n",
      "POS      1.00\n",
      "NEG      1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python -m spacy evaluate resources/model/model-best/ resources/test.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pepline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POS': 0.9750515222549438, 'NEG': 0.024948548525571823} - :)\n",
      "{'POS': 0.4973682463169098, 'NEG': 0.5026317238807678} - Estou muito triste hoje\n",
      "{'POS': 0.8404939770698547, 'NEG': 0.15950603783130646} - Estou muito feliz hoje\n"
     ]
    }
   ],
   "source": [
    "texts = [\":)\", \"Estou muito triste hoje\", \"Estou muito feliz hoje\"]\n",
    "\n",
    "nlp = spacy.load(\"resources/model/model-best\")\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(preprocessing(text))\n",
    "    print(doc.cats,  \"-\",  text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get config from Languaje object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[paths]\n",
      "train = \"resources/train.spacy\"\n",
      "dev = \"resources/dev.spacy\"\n",
      "vectors = null\n",
      "init_tok2vec = null\n",
      "\n",
      "[system]\n",
      "gpu_allocator = null\n",
      "seed = 0\n",
      "\n",
      "[nlp]\n",
      "lang = \"pt\"\n",
      "pipeline = [\"textcat\"]\n",
      "batch_size = 1000\n",
      "disabled = []\n",
      "before_creation = null\n",
      "after_creation = null\n",
      "after_pipeline_creation = null\n",
      "tokenizer = {\"@tokenizers\":\"spacy.Tokenizer.v1\"}\n",
      "vectors = {\"@vectors\":\"spacy.Vectors.v1\"}\n",
      "\n",
      "[components]\n",
      "\n",
      "[components.textcat]\n",
      "factory = \"textcat\"\n",
      "scorer = {\"@scorers\":\"spacy.textcat_scorer.v2\"}\n",
      "threshold = 0.0\n",
      "\n",
      "[components.textcat.model]\n",
      "@architectures = \"spacy.TextCatBOW.v3\"\n",
      "exclusive_classes = true\n",
      "ngram_size = 1\n",
      "no_output_layer = false\n",
      "length = 262144\n",
      "nO = null\n",
      "\n",
      "[corpora]\n",
      "\n",
      "[corpora.dev]\n",
      "@readers = \"spacy.Corpus.v1\"\n",
      "path = ${paths.dev}\n",
      "max_length = 0\n",
      "gold_preproc = false\n",
      "limit = 0\n",
      "augmenter = null\n",
      "\n",
      "[corpora.train]\n",
      "@readers = \"spacy.Corpus.v1\"\n",
      "path = ${paths.train}\n",
      "max_length = 0\n",
      "gold_preproc = false\n",
      "limit = 0\n",
      "augmenter = null\n",
      "\n",
      "[training]\n",
      "dev_corpus = \"corpora.dev\"\n",
      "train_corpus = \"corpora.train\"\n",
      "seed = ${system.seed}\n",
      "gpu_allocator = ${system.gpu_allocator}\n",
      "dropout = 0.1\n",
      "accumulate_gradient = 1\n",
      "patience = 1600\n",
      "max_epochs = 0\n",
      "max_steps = 20000\n",
      "eval_frequency = 200\n",
      "frozen_components = []\n",
      "annotating_components = []\n",
      "before_to_disk = null\n",
      "before_update = null\n",
      "\n",
      "[training.batcher]\n",
      "@batchers = \"spacy.batch_by_words.v1\"\n",
      "discard_oversize = false\n",
      "tolerance = 0.2\n",
      "get_length = null\n",
      "\n",
      "[training.batcher.size]\n",
      "@schedules = \"compounding.v1\"\n",
      "start = 100\n",
      "stop = 1000\n",
      "compound = 1.001\n",
      "t = 0.0\n",
      "\n",
      "[training.logger]\n",
      "@loggers = \"spacy.ConsoleLogger.v1\"\n",
      "progress_bar = false\n",
      "\n",
      "[training.optimizer]\n",
      "@optimizers = \"Adam.v1\"\n",
      "beta1 = 0.9\n",
      "beta2 = 0.999\n",
      "L2_is_weight_decay = true\n",
      "L2 = 0.01\n",
      "grad_clip = 1.0\n",
      "use_averages = false\n",
      "eps = 0.00000001\n",
      "learn_rate = 0.001\n",
      "\n",
      "[training.score_weights]\n",
      "cats_score = 1.0\n",
      "cats_score_desc = null\n",
      "cats_micro_p = null\n",
      "cats_micro_r = null\n",
      "cats_micro_f = null\n",
      "cats_macro_p = null\n",
      "cats_macro_r = null\n",
      "cats_macro_f = null\n",
      "cats_macro_auc = null\n",
      "cats_f_per_type = null\n",
      "\n",
      "[pretraining]\n",
      "\n",
      "[initialize]\n",
      "vectors = ${paths.vectors}\n",
      "init_tok2vec = ${paths.init_tok2vec}\n",
      "vocab_data = null\n",
      "lookups = null\n",
      "before_init = null\n",
      "after_init = null\n",
      "\n",
      "[initialize.components]\n",
      "\n",
      "[initialize.tokenizer]\n"
     ]
    }
   ],
   "source": [
    "print(nlp.config.to_str())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
